{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199c0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from random import randint\n",
    "from neural_process import NeuralProcessImg\n",
    "from torch import nn\n",
    "from torch.distributions.kl import kl_divergence\n",
    "from utils import (context_target_split, batch_context_target_mask,\n",
    "                   img_mask_to_np_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910fe024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralProcessTrainer():\n",
    "    \"\"\"\n",
    "    Class to handle training of Neural Processes for functions and images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    device : torch.device\n",
    "\n",
    "    neural_process : neural_process.NeuralProcess or NeuralProcessImg instance\n",
    "\n",
    "    optimizer : one of torch.optim optimizers\n",
    "\n",
    "    num_context_range : tuple of ints\n",
    "        Number of context points will be sampled uniformly in the range given\n",
    "        by num_context_range.\n",
    "\n",
    "    num_extra_target_range : tuple of ints\n",
    "        Number of extra target points (as we always include context points in\n",
    "        target points, i.e. context points are a subset of target points) will\n",
    "        be sampled uniformly in the range given by num_extra_target_range.\n",
    "\n",
    "    print_freq : int\n",
    "        Frequency with which to print loss information during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, device, neural_process, optimizer, num_context_range,\n",
    "                 num_extra_target_range, print_freq=100):\n",
    "        self.device = device\n",
    "        self.neural_process = neural_process\n",
    "        self.optimizer = optimizer\n",
    "        self.num_context_range = num_context_range\n",
    "        self.num_extra_target_range = num_extra_target_range\n",
    "        self.print_freq = print_freq\n",
    "\n",
    "        # Check if neural process is for images\n",
    "        self.is_img = isinstance(self.neural_process, NeuralProcessImg)\n",
    "        self.steps = 0\n",
    "        self.epoch_loss_history = []\n",
    "\n",
    "    def train(self, data_loader, epochs):\n",
    "        \"\"\"\n",
    "        Trains Neural Process.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataloader : torch.utils.DataLoader instance\n",
    "\n",
    "        epochs : int\n",
    "            Number of epochs to train for.\n",
    "        \"\"\"\n",
    "        total_losss = []\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.\n",
    "            for i, data in enumerate(data_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Sample number of context and target points\n",
    "                num_context = randint(*self.num_context_range)\n",
    "                num_extra_target = randint(*self.num_extra_target_range)\n",
    "\n",
    "                # Create context and target points and apply neural process\n",
    "                if self.is_img:\n",
    "                    img, _ = data  # data is a tuple (img, label)\n",
    "                    batch_size = img.size(0)\n",
    "                    context_mask, target_mask = \\\n",
    "                        batch_context_target_mask(self.neural_process.img_size,\n",
    "                                                  num_context, num_extra_target,\n",
    "                                                  batch_size)\n",
    "\n",
    "                    img = img.to(self.device)\n",
    "                    context_mask = context_mask.to(self.device)\n",
    "                    target_mask = target_mask.to(self.device)\n",
    "\n",
    "                    p_y_pred, q_target, q_context = \\\n",
    "                        self.neural_process(img, context_mask, target_mask)\n",
    "\n",
    "                    # Calculate y_target as this will be required for loss\n",
    "                    _, y_target = img_mask_to_np_input(img, target_mask)\n",
    "                else:\n",
    "                    x, y = data\n",
    "                    x_context, y_context, x_target, y_target = \\\n",
    "                        context_target_split(x, y, num_context, num_extra_target)\n",
    "                    p_y_pred, q_target, q_context = \\\n",
    "                        self.neural_process(x_context, y_context, x_target, y_target)\n",
    "\n",
    "                loss = self._loss(p_y_pred, y_target, q_target, q_context)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                self.steps += 1\n",
    "\n",
    "                if self.steps % self.print_freq == 0:\n",
    "                    print(\"iteration {}, loss {:.3f}\".format(self.steps, loss.item()))\n",
    "\n",
    "            print(\"Epoch: {}, Avg_loss: {}\".format(epoch, epoch_loss / len(data_loader)))\n",
    "            self.epoch_loss_history.append(epoch_loss / len(data_loader))\n",
    "            total_loss.append(epoch_loss)\n",
    "        return total_loss\n",
    "\n",
    "    def _loss(self, p_y_pred, y_target, q_target, q_context):\n",
    "        \"\"\"\n",
    "        Computes Neural Process loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        p_y_pred : one of torch.distributions.Distribution\n",
    "            Distribution over y output by Neural Process.\n",
    "\n",
    "        y_target : torch.Tensor\n",
    "            Shape (batch_size, num_target, y_dim)\n",
    "\n",
    "        q_target : one of torch.distributions.Distribution\n",
    "            Latent distribution for target points.\n",
    "\n",
    "        q_context : one of torch.distributions.Distribution\n",
    "            Latent distribution for context points.\n",
    "        \"\"\"\n",
    "        # Log likelihood has shape (batch_size, num_target, y_dim). Take mean\n",
    "        # over batch and sum over number of targets and dimensions of y\n",
    "        log_likelihood = p_y_pred.log_prob(y_target).mean(dim=0).sum()\n",
    "        # KL has shape (batch_size, r_dim). Take mean over batch and sum over\n",
    "        # r_dim (since r_dim is dimension of normal distribution)\n",
    "        kl = kl_divergence(q_target, q_context).mean(dim=0).sum()\n",
    "        return -log_likelihood + kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c08a668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
